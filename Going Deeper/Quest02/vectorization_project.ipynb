{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "059df3a3",
      "metadata": {
        "id": "059df3a3"
      },
      "source": [
        "# 뉴스 카테고리 다중분류"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc60ed3",
      "metadata": {
        "id": "ccc60ed3"
      },
      "source": [
        "## 프로젝트 설명"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 변경하고 조합해서 성능을 올리는 방법도 있지만 사용하는 단어의 수에 따라 성능이 달라질 수도 있다.\n",
        "\n",
        "중요도가 낮은 단어들까지 포함해 너무 많은 단어를 사용하는 경우나 너무 적은 단어들을 사용하는 경우 성능이 낮아질 수 있다.\n",
        "\n",
        "이렇게 변화된 단어의 수는 어떤 모델을 사용하느냐에 따라 유리할 수도, 불리할 수도 있다.\n",
        "\n",
        "따라서 모든 단어를 사용하는 경우, 빈도수 상위 3000개, 5000개, 10000개, 20000개의 단어만 사용하는 경우 총 5가지의 경우에 대해서 8개의 머신 러닝 모델과 1개의 딥러닝 모델을 사용하여 성능 분석을 진행한다.\n",
        "\n",
        "모델의 종류는 다음과 같다.\n",
        "- Naive Bayse\n",
        "- Complement Naive Bayse\n",
        "- Logistic Regression\n",
        "- Support Vector Machine\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- Gradient Boosting Tree\n",
        "- Voting\n",
        "- 1D-CNN\n",
        "\n",
        "M2 팀원 세 명이 각각 세 개의 모델을 담당하여 실험 진행 후 결과를 취합하는 방식으로 진행한다.\n",
        "\n",
        "따라서 이번 노트북 파일에는 9개의 모델 중 Logistic Regression, Random Forest, 1D-CNN을 사용한 실험만 진행하였다."
      ],
      "metadata": {
        "id": "T4eA9-YL0vuh"
      },
      "id": "T4eA9-YL0vuh"
    },
    {
      "cell_type": "markdown",
      "id": "3f8eeb29",
      "metadata": {
        "id": "3f8eeb29"
      },
      "source": [
        "## 프로젝트 루브릭"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|학습 목표|평가 기준|\n",
        "|---------|---------|\n",
        "|분류 모델의 accuracy가 기준 이상 높게 나왔는가?|3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다.|\n",
        "|분류 모델의 F1 score가 기준 이상 높게 나왔는가?|Vocabulary size에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, <br>해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.|\n",
        "|딥러닝 모델을 활용해 성능이 비교 및 확인되었는가?|동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다.|"
      ],
      "metadata": {
        "id": "nMXClIzQ11Ni"
      },
      "id": "nMXClIzQ11Ni"
    },
    {
      "cell_type": "markdown",
      "id": "a88637c8",
      "metadata": {
        "id": "a88637c8"
      },
      "source": [
        "# 사전 환경 세팅"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f224e17",
      "metadata": {
        "id": "7f224e17"
      },
      "source": [
        "## Colab 환경 세팅 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "51d83d5c",
      "metadata": {
        "id": "51d83d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9f0674-c51e-4ea1-ebab-ead7ce20bd93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/AIFFEL/Deep_Dive/work/reuters_classification\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/AIFFEL/Deep_Dive/work/reuters_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a749c86c",
      "metadata": {
        "id": "a749c86c"
      },
      "source": [
        "## LMS 환경 세팅 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bb3e0f30",
      "metadata": {
        "id": "bb3e0f30"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/work/reuters_classification/data\n",
        "!ln -s ~/data/* ~/work/reuters_classification/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867a477e",
      "metadata": {
        "id": "867a477e"
      },
      "source": [
        "## 환경 세팅"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "496649e5",
      "metadata": {
        "id": "496649e5"
      },
      "source": [
        "# 라이브러리 설치 및 호출"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcf4f1e5",
      "metadata": {
        "id": "dcf4f1e5"
      },
      "source": [
        "## 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy sentencepiece soynlp scikit-learn\n",
        "!apt-get install -y openjdk-17-jdk\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd ./Mecab-ko-for-Google-Colab/\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh\n",
        "%cd /content/drive/MyDrive/AIFFEL/Deep_Dive/work/reuters_classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAPfD-wk3fA5",
        "outputId": "1880d9b2-224a-4ee5-a09e-d7dcae98a489"
      },
      "id": "IAPfD-wk3fA5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Collecting soynlp\n",
            "  Downloading soynlp-0.0.493-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.12/dist-packages (from soynlp) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from soynlp) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.8/416.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (495 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.9/495.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy, soynlp\n",
            "Successfully installed JPype1-1.6.0 konlpy-0.6.0 soynlp-0.0.493\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jre session-migration x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libxt-doc openjdk-17-demo openjdk-17-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-17-jdk openjdk-17-jre session-migration\n",
            "  x11-utils\n",
            "0 upgraded, 24 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 8,207 kB of archives.\n",
            "After this operation, 24.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [232 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [1,522 kB]\n",
            "Fetched 8,207 kB in 2s (3,692 kB/s)\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "(Reading database ... 121703 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../07-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../08-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../09-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../10-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../12-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../13-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../14-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../15-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../16-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../17-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../18-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../19-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../20-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../21-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../22-openjdk-17-jre_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jre:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../23-openjdk-17-jdk_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up openjdk-17-jre:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n",
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 138 (delta 26), reused 22 (delta 8), pack-reused 91 (from 1)\u001b[K\n",
            "Receiving objects: 100% (138/138), 1.72 MiB | 12.03 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "/content/drive/MyDrive/AIFFEL/Deep_Dive/work/reuters_classification/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (1.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2025-11-17 04:25:00--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 13.200.41.135, 13.200.41.136, 13.200.41.134, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|13.200.41.135|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNL7NXDFGB&Signature=mSjv9d0OfdxhlX7zAzL5rEavLKQ%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEN3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDA1AiERU3q8nPK5tFtO5YtKwBpqg5hpjyN4Kiz8EFbCgIgb07tH7QPUufEnVHyaMb0hfreT11Hbqck4cGM6g0Coz8qsAIIpf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDAzkHH2e3%2B14SI1y6yqEAg%2BpAPjENA0ypap%2BIZWSAlK4JkIj27NRou8BZomZg89j1cez%2B9TUfZ%2B7ewsJvVdWiPb9doLLPFU%2B4hsh1qJ5RUTbbNhKT3aLAYKMy%2BpH69Eit7ax8SjZeu6zxEhw23cRNuUYz91Gewq3CZ%2B1H1kyfRXBvGT4140gsl%2FGkbzX%2BNvSpWoD3wcofJDs1Un%2FhaFEx9A0PiSm%2FjyOafpXHkho8ZbUE6qxhv4zIB9YvsR5LqjW5npuDY1nfkFUZOgYesyy6tS80k%2FzLNmQT5Vyv9CM9wDqzYwhvEuVOtw6tEWs3eTkKOh2W6UMot6n4WTNmM%2F4VXknWzO1Y0siX%2BBQUJKGP78%2Bm5hAMPHC6sgGOp0BOx4YqoXw7pctdvDLvOgxGPE5j5b%2FLVxmXoXGNuo%2BNJkrjM972frQvF9eaiwzZ2REQnZwrRuDjJ8kUo33X30yf0HhC4o1KGIZ%2BwIfh11%2BJpxUz1U8HQnOy5NnDJohCOURgifw2JJ1FT2dPLdhwHca11h5pMxPE%2BEPyyh7zo6eByxLCWkI9JuLEhFarchjoSrqpUN0zFzFiil1zZnURQ%3D%3D&Expires=1763354745 [following]\n",
            "--2025-11-17 04:25:01--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNL7NXDFGB&Signature=mSjv9d0OfdxhlX7zAzL5rEavLKQ%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEN3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDA1AiERU3q8nPK5tFtO5YtKwBpqg5hpjyN4Kiz8EFbCgIgb07tH7QPUufEnVHyaMb0hfreT11Hbqck4cGM6g0Coz8qsAIIpf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDAzkHH2e3%2B14SI1y6yqEAg%2BpAPjENA0ypap%2BIZWSAlK4JkIj27NRou8BZomZg89j1cez%2B9TUfZ%2B7ewsJvVdWiPb9doLLPFU%2B4hsh1qJ5RUTbbNhKT3aLAYKMy%2BpH69Eit7ax8SjZeu6zxEhw23cRNuUYz91Gewq3CZ%2B1H1kyfRXBvGT4140gsl%2FGkbzX%2BNvSpWoD3wcofJDs1Un%2FhaFEx9A0PiSm%2FjyOafpXHkho8ZbUE6qxhv4zIB9YvsR5LqjW5npuDY1nfkFUZOgYesyy6tS80k%2FzLNmQT5Vyv9CM9wDqzYwhvEuVOtw6tEWs3eTkKOh2W6UMot6n4WTNmM%2F4VXknWzO1Y0siX%2BBQUJKGP78%2Bm5hAMPHC6sgGOp0BOx4YqoXw7pctdvDLvOgxGPE5j5b%2FLVxmXoXGNuo%2BNJkrjM972frQvF9eaiwzZ2REQnZwrRuDjJ8kUo33X30yf0HhC4o1KGIZ%2BwIfh11%2BJpxUz1U8HQnOy5NnDJohCOURgifw2JJ1FT2dPLdhwHca11h5pMxPE%2BEPyyh7zo6eByxLCWkI9JuLEhFarchjoSrqpUN0zFzFiil1zZnURQ%3D%3D&Expires=1763354745\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.236.153, 54.231.234.169, 16.182.68.1, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.236.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.22MB/s    in 1.1s    \n",
            "\n",
            "2025-11-17 04:25:03 (1.22 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2025-11-17 04:27:11--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 13.200.41.136, 13.200.41.135, 13.200.41.134, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|13.200.41.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNECWXOKXX&Signature=5H8PQLr2dvxmq070mCHBJSq%2FrMk%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEN3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIBRA7Py%2BbQ60naPMqHvP2lGAGGZwac%2BvvGYSpS%2FdG86cAiBUWk9pYtTgbAI5ESp%2BZhoZ3kgrq%2FpKTvd1hUvchiCpAyqwAgim%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDk4NDUyNTEwMTE0NiIMGyvgJqkKDuY7qy91KoQC6DxeaMiy9I8hU%2FbzT%2BPml%2FO9GX%2F1HJiJhOdDgGx8YW1DEkIgjveA5yxlI%2Fojd0xYLaumxo1SzHMDwawj83H%2Boyau3WrcMn7mK%2B%2BuKQMFmm4kPb0Ll807qcLSbDJ2M04UaMbwjftxBloQHP8DTzECkBdM2f2htF3G70Pv%2BBZ2eXlHySXP%2FblGuwphelV%2BXLniBl1IgQpFf3dXVOdbovrc9lw0k2vLbs7JSK9RbK6GnpOVRrqbcbpXKT1ClH7C%2FSLdaU7%2BBt3sG5GsjZp%2BKkIBVskOkPBiR5SEQ%2BvJcypNF5IN3J4Vt0vM34%2BZQ3cgysjpBZggn%2BLbkipA%2BvZ4GVNBNBh5O3Yw4sXqyAY6ngFWXedHLArlwUBO8QMx426t3RosEaNWQb41nv6dcRTpSVPTMjqFuwbrE2jdJl%2BUnDhN13Ke%2B9HZZT0LT4CL2MBEZombXQ%2FtV6CNM%2FNhrGI5QX7cCV1oBLwmWHyYeZ%2BAx6OCEMKSsTOOla0irUCOrzq%2F86D9YBCOLT18Yf3Gkm%2Bhbda4fBOIygIfXpLwoa2zRfhhxUYWwh3CRFcyufkPEA%3D%3D&Expires=1763355114 [following]\n",
            "--2025-11-17 04:27:11--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNECWXOKXX&Signature=5H8PQLr2dvxmq070mCHBJSq%2FrMk%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEN3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIBRA7Py%2BbQ60naPMqHvP2lGAGGZwac%2BvvGYSpS%2FdG86cAiBUWk9pYtTgbAI5ESp%2BZhoZ3kgrq%2FpKTvd1hUvchiCpAyqwAgim%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDk4NDUyNTEwMTE0NiIMGyvgJqkKDuY7qy91KoQC6DxeaMiy9I8hU%2FbzT%2BPml%2FO9GX%2F1HJiJhOdDgGx8YW1DEkIgjveA5yxlI%2Fojd0xYLaumxo1SzHMDwawj83H%2Boyau3WrcMn7mK%2B%2BuKQMFmm4kPb0Ll807qcLSbDJ2M04UaMbwjftxBloQHP8DTzECkBdM2f2htF3G70Pv%2BBZ2eXlHySXP%2FblGuwphelV%2BXLniBl1IgQpFf3dXVOdbovrc9lw0k2vLbs7JSK9RbK6GnpOVRrqbcbpXKT1ClH7C%2FSLdaU7%2BBt3sG5GsjZp%2BKkIBVskOkPBiR5SEQ%2BvJcypNF5IN3J4Vt0vM34%2BZQ3cgysjpBZggn%2BLbkipA%2BvZ4GVNBNBh5O3Yw4sXqyAY6ngFWXedHLArlwUBO8QMx426t3RosEaNWQb41nv6dcRTpSVPTMjqFuwbrE2jdJl%2BUnDhN13Ke%2B9HZZT0LT4CL2MBEZombXQ%2FtV6CNM%2FNhrGI5QX7cCV1oBLwmWHyYeZ%2BAx6OCEMKSsTOOla0irUCOrzq%2F86D9YBCOLT18Yf3Gkm%2Bhbda4fBOIygIfXpLwoa2zRfhhxUYWwh3CRFcyufkPEA%3D%3D&Expires=1763355114\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.229.153, 52.217.122.121, 3.5.11.201, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.229.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  10.7MB/s    in 5.1s    \n",
            "\n",
            "2025-11-17 04:27:17 (9.36 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n",
            "/content/drive/MyDrive/AIFFEL/Deep_Dive/work/reuters_classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14c31571",
      "metadata": {
        "id": "14c31571"
      },
      "source": [
        "## 라이브러리 호출"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "WZ_4d9ZwDTMj"
      },
      "id": "WZ_4d9ZwDTMj",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score #정확도 계산\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WN8NtvDd2FsB"
      },
      "id": "WN8NtvDd2FsB",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 버전 확인"
      ],
      "metadata": {
        "id": "_WTO835IC9vj"
      },
      "id": "_WTO835IC9vj"
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(matplotlib.__version__)\n",
        "print(sns.__version__)\n",
        "print(np.__version__)\n",
        "print(pd.__version__)\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZKcPckiDADR",
        "outputId": "81f8c174-d84d-4498-dc4b-19440259251b"
      },
      "id": "VZKcPckiDADR",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n",
            "3.10.0\n",
            "0.13.2\n",
            "2.0.2\n",
            "2.2.2\n",
            "1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "679c5632",
      "metadata": {
        "id": "679c5632"
      },
      "source": [
        "# 데이터 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb5ee027",
      "metadata": {
        "id": "fb5ee027"
      },
      "source": [
        "## 데이터 다운로드 및 열기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"./data/\"\n",
        "\n",
        "x_train = np.load(data_dir + \"x_train.npy\", allow_pickle=True)\n",
        "y_train = np.load(data_dir + \"y_train.npy\", allow_pickle=True)\n",
        "x_test = np.load(data_dir + \"x_test.npy\", allow_pickle=True)\n",
        "y_test = np.load(data_dir + \"y_test.npy\", allow_pickle=True)\n",
        "\n",
        "x_train_seq = np.load(data_dir + \"x_train.npy\", allow_pickle=True)\n",
        "x_test_seq = np.load(data_dir + \"x_test.npy\", allow_pickle=True)"
      ],
      "metadata": {
        "id": "ONSHro8H3qOb"
      },
      "id": "ONSHro8H3qOb",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6152857e",
      "metadata": {
        "id": "6152857e"
      },
      "source": [
        "## 데이터 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
        "print('테스트 샘플의 수: {}'.format(len(x_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6_SSyk_36ab",
        "outputId": "38d78762-2244-45fd-9b58-4626200a171b"
      },
      "id": "s6_SSyk_36ab",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플의 수: 8982\n",
            "테스트 샘플의 수: 2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(x_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKcL2Te538gI",
        "outputId": "b7d28d22-5f93-417b-c796-83cc119652e9"
      },
      "id": "DKcL2Te538gI",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abqEQLYJ38mB",
        "outputId": "73e94db6-2ffb-4930-d32c-ea53491771a2"
      },
      "id": "abqEQLYJ38mB",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = max(y_train) + 1\n",
        "print('클래스의 수 : {}'.format(num_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNHyPdfQ383x",
        "outputId": "36852474-1866-4c02-954b-7024828e9bcc"
      },
      "id": "RNHyPdfQ383x",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스의 수 : 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8cd4df9",
      "metadata": {
        "id": "f8cd4df9"
      },
      "source": [
        "## 데이터 시각화"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
        "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
        "\n",
        "plt.hist([len(s) for s in x_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "OJMy5Q3d387Z",
        "outputId": "e73d25b4-6687-470c-f4db-e248e5cccab1"
      },
      "id": "OJMy5Q3d387Z",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 뉴스의 최대 길이 :2376\n",
            "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axe = plt.subplots(ncols=1)\n",
        "fig.set_size_inches(11,5)\n",
        "sns.countplot(x=y_train)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "HCA4tEik38_B",
        "outputId": "b5d7738d-8382-49fd-f991-94c0b71d1e7e"
      },
      "id": "HCA4tEik38_B",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1100x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "print(\"각 클래스 빈도수:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6IkKCGF39CD",
        "outputId": "1f035cd8-508f-4cc9-c6dc-0551cffb9f3e"
      },
      "id": "p6IkKCGF39CD",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 클래스 빈도수:\n",
            "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
            "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
            "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
            "    42   43   44   45]\n",
            " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
            "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
            "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
            "    13   21   12   18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g_xJDRB739E5"
      },
      "id": "g_xJDRB739E5",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "50e7cc0e",
      "metadata": {
        "id": "50e7cc0e"
      },
      "source": [
        "## 데이터 복원하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "!wget https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
        "\n",
        "# 1. 파일 열기\n",
        "with open('reuters_word_index.json', 'r', encoding='utf-8') as f:\n",
        "    # 2. JSON 로드\n",
        "    word_index = json.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmlRYcc09x1R",
        "outputId": "9172736b-136c-411f-b831-542a3304534e"
      },
      "id": "fmlRYcc09x1R",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-17 04:28:08--  https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.207, 142.251.10.207, 142.251.12.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 550378 (537K) [application/json]\n",
            "Saving to: ‘reuters_word_index.json.5’\n",
            "\n",
            "reuters_word_index. 100%[===================>] 537.48K   667KB/s    in 0.8s    \n",
            "\n",
            "2025-11-17 04:28:09 (667 KB/s) - ‘reuters_word_index.json.5’ saved [550378/550378]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index['the']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfz3Spb990Ih",
        "outputId": "b9b940c3-bbd0-45a0-8f2c-651e6c165f87"
      },
      "id": "dfz3Spb990Ih",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index['it']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdz2VbIY90QH",
        "outputId": "04fcb19b-ad55-4ed8-e5b3-2107c0a0992d"
      },
      "id": "Fdz2VbIY90QH",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = { index+3 : word for word, index in word_index.items() }"
      ],
      "metadata": {
        "id": "LFK5cdh390TZ"
      },
      "id": "LFK5cdh390TZ",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(index_to_word[4])\n",
        "print(index_to_word[16])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkkhODhw90Wp",
        "outputId": "f8ac437a-b0a3-42d5-aa80-79c0e367c1af"
      },
      "id": "VkkhODhw90Wp",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\n",
            "it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token"
      ],
      "metadata": {
        "id": "o86NsLBa90Z0"
      },
      "id": "o86NsLBa90Z0",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join([index_to_word[index] for index in x_train[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVSOHFJC90cp",
        "outputId": "362b353c-4a3f-4bac-a2d0-3ca90ef0c1bc"
      },
      "id": "JVSOHFJC90cp",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_train = decoded\n",
        "print(len(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjOmezz190fh",
        "outputId": "86c0ee08-4189-453f-945d-574e895b2dde"
      },
      "id": "KjOmezz190fh",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test데이터도 변환해주세요!\n",
        "\n",
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5SfcWOe90iR",
        "outputId": "3748b5f2-dba5-402c-d39f-1a395d86b3f5"
      },
      "id": "Y5SfcWOe90iR",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cmUVx_U90k5",
        "outputId": "c774957c-9d8f-4e86-f89a-de1a05985b21"
      },
      "id": "8cmUVx_U90k5",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3',\n",
              " '<sos> generale de banque sa lt <unk> br and lt heller overseas corp of chicago have each taken 50 pct stakes in <unk> company sa <unk> factors generale de banque said in a statement it gave no financial details of the transaction sa <unk> <unk> turnover in 1986 was 17 5 billion belgian francs reuter 3',\n",
              " '<sos> shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in <unk> corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national <unk> inc of 11 8 mln and <unk> corp of 15 6 mln reuter 3',\n",
              " \"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely <unk> borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in <unk> financial eligibility standards indicated as many as one half of <unk> borrowers who received new loans from the agency in 1986 would be <unk> under the proposed system the agency has proposed evaluating <unk> credit using a variety of financial ratios instead of relying solely on <unk> ability senate agriculture committee chairman patrick leahy d vt <unk> the proposed eligibility changes telling <unk> administrator <unk> clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to <unk> its 70 billion dlr loan portfolio in a <unk> yet <unk> manner crowley of gao <unk> <unk> arm said the proposed credit <unk> system attempted to ensure that <unk> would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\",\n",
              " '<sos> seton co said its board has received a proposal from chairman and chief executive officer philip d <unk> to acquire seton for 15 75 dlrs per share in cash seton said the acquisition bid is subject to <unk> arranging the necessary financing it said he intends to ask other members of senior management to participate the company said <unk> owns 30 pct of seton stock and other management members another 7 5 pct seton said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kceLpbMk90nx",
        "outputId": "d5af553a-31f9-4631-af44-67924f7d967d"
      },
      "id": "kceLpbMk90nx",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3',\n",
              " \"<sos> philippine sugar production in the 1987 88 crop year ending august has been set at 1 6 mln tonnes up from a provisional 1 3 mln tonnes this year sugar regulatory administration <unk> chairman <unk> yulo said yulo told reuters a survey during the current milling season which ends next month showed the 1986 87 estimate would almost certainly be met he said at least 1 2 mln tonnes of the 1987 88 crop would be earmarked for domestic consumption yulo said about 130 000 tonnes would be set aside for the u s sugar quota 150 000 tonnes for strategic reserves and 50 000 tonnes would be sold on the world market he said if the government approved a long standing <unk> recommendation to manufacture ethanol the project would take up another 150 000 tonnes slightly raising the target the government for its own reasons has been delaying approval of the project but we expect it to come through by july yulo said ethanol could make up five pct of gasoline cutting the oil import bill by about 300 mln pesos yulo said three major philippine <unk> were ready to start manufacturing ethanol if the project was approved the ethanol project would result in employment for about 100 000 people sharply reducing those thrown out of work by depressed world sugar prices and a <unk> domestic industry production quotas set for the first time in 1987 88 had been submitted to president corazon aquino i think the president would rather wait <unk> the new congress <unk> after the may elections he said but there is really no need for such quotas we are right now producing just slightly over our own consumption level the producers have never enjoyed such high prices yulo said adding sugar was currently selling locally for 320 pesos per <unk> up from 190 pesos last august yulo said prices were driven up because of speculation following the <unk> bid to control production we are no longer concerned so much with the world market he said adding producers in the <unk> region had learned from their <unk> and diversified into corn and <unk> farming and <unk> production he said diversification into products other than ethanol was also possible within the sugar industry the <unk> long ago <unk> their <unk> yulo said they have 300 sugar mills compared with our 41 but they <unk> many of them and diversified production we want to call this a <unk> <unk> instead of the sugar industry he said sugarcane could be fed to pigs and livestock used for <unk> <unk> or used in room <unk> when you cut sugarcane you don't even have to produce sugar he said yulo said the philippines was lobbying for a renewal of the international sugar agreement which expired in 1984 as a major sugar producer we are urging them to write a new agreement which would revive world prices yulo said if there is no agreement world prices will always be depressed particularly because the european community is <unk> its producers and dumping sugar on the markets he said current world prices holding steady at about 7 60 cents per pound were <unk> for the philippines where production costs ranged from 12 to 14 cents a pound if the price holds steady for a while at 7 60 cents i expect the level to rise to about 11 cents a pound by the end of this year he said yulo said economists forecast a bullish sugar market by 1990 with world consumption <unk> production he said sugar markets were holding up despite <unk> from artificial sweeteners and high fructose corn syrup but we are not happy with the reagan administration he said since <unk> we have been regular suppliers of sugar to the u s in 1982 when they restored the quota system they cut <unk> in half without any justification manila was <unk> watching washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december slashed its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 yulo said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\",\n",
              " \"<sos> the agriculture department's widening of louisiana gulf differentials will affect county posted prices for number two yellow corn in ten states a usda official said all counties in iowa will be affected as will counties which use the gulf to price corn in illinois indiana tennessee kentucky missouri mississippi arkansas alabama and louisiana said <unk> <unk> deputy director of commodity operations division for the usda usda last night notified the grain industry that effective immediately all gulf differentials used to price interior corn would be widened on a sliding scale basis of four to eight cts depending on what the differential is usda's action was taken to lower excessively high posted county prices for corn caused by high gulf prices we've been following this louisiana gulf situation for a month and we don't think it's going to get back in line in any nearby time <unk> said <unk> said usda will probably narrow back the gulf differentials when and if gulf prices <unk> if we're off the mark now because we're too high wouldn't we be as much off the mark if we're too low he said while forecasting more adjustments if gulf prices fall <unk> said no other changes in usda's price system are being planned right now we don't tinker we don't make changes <unk> and we don't make changes often he said reuter 3\",\n",
              " '<sos> <unk> <unk> oil and gas partnership said it completed the sale of interests in two major oil and gas fields to lt energy assets international corp for 21 mln dlrs the company said it sold about one half of its 50 pct interest in the oak hill and north <unk> fields its two largest producing properties it said it used about 20 mln dlrs of the proceeds to <unk> principal on its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial covenants and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the <unk> exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the oak hill field reuter 3',\n",
              " '<sos> strong south <unk> winds were keeping many vessels trapped in the ice off the finnish and swedish coasts in one of the worst icy periods in the baltic for many years the finnish board of navigation said in finland and sweden up to 50 vessels were reported to be stuck in the ice and even the largest of the <unk> <unk> were having difficulties in breaking through to the <unk> ships <unk> officials said however icy conditions in the southern baltic at the soviet oil ports of <unk> and <unk> had eased they said weather officials in neighbouring sweden said the icy conditions in the baltic were the worst for 30 years with ships fighting a losing battle to keep moving in the coastal stretches of the gulf of <unk> which <unk> finland and sweden the ice is up to one <unk> thick with <unk> and <unk> packing it into almost <unk> walls three metres high swedish <unk> officials said weather forecasts say winds may ease during the weekend but a further drop in temperature could bring shipping to a standstill the officials said reuter 3']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "855cffc4",
      "metadata": {
        "id": "855cffc4"
      },
      "source": [
        "# 벡터화하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtmvector = CountVectorizer()\n",
        "x_train_dtm = dtmvector.fit_transform(x_train)\n",
        "print(x_train_dtm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4c8TUJy-FHB",
        "outputId": "c504603d-4e5c-47f3-f539-d4cb011267aa"
      },
      "id": "A4c8TUJy-FHB",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 9670)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "print(tfidfv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-ZanqUC-FtR",
        "outputId": "eacd3c92-451f-4a0b-acb8-814d4a3b0612"
      },
      "id": "f-ZanqUC-FtR",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 9670)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\""
      ],
      "metadata": {
        "id": "EzByoQh9MgRL"
      },
      "id": "EzByoQh9MgRL",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "def build_tfidf(x_train_texts, x_test_texts, max_features=None):\n",
        "    \"\"\"\n",
        "    x_train_texts, x_test_texts: 리스트[str]\n",
        "    max_features: vocab_size (None이면 전체 단어 사용)\n",
        "    return: tfidfv_train, tfidfv_test, fitted_vectorizer\n",
        "    \"\"\"\n",
        "    dtmvector = CountVectorizer(max_features=max_features)\n",
        "    x_train_dtm = dtmvector.fit_transform(x_train_texts)\n",
        "\n",
        "    tfidf_transformer = TfidfTransformer()\n",
        "    tfidfv_train = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "\n",
        "    x_test_dtm = dtmvector.transform(x_test_texts)\n",
        "    tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
        "\n",
        "    return tfidfv_train, tfidfv_test, dtmvector"
      ],
      "metadata": {
        "id": "2UPXDRqsRrar"
      },
      "id": "2UPXDRqsRrar",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfv, tfidfv_test, vectorizer = build_tfidf(x_train, x_test, max_features=None)"
      ],
      "metadata": {
        "id": "cBpLzy21ScJJ"
      },
      "id": "cBpLzy21ScJJ",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5e19a9a5",
      "metadata": {
        "id": "5e19a9a5"
      },
      "source": [
        "# 가설 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d5bd9d",
      "metadata": {
        "id": "26d5bd9d"
      },
      "source": [
        "## 모델에 따라 성능이 달라질 것이다.\n",
        "통제 변인 : vocab_size=5000, 전처리 방식, 사용 데이터\n",
        "\n",
        "종속 변인 : 모델 종류 (Naive Bayse, Complement Naive Bayse, Logistic Regression, SVM, Decision Tree, Random Forest, Gradient Boosting Tree, Voting, 1D-CNN)\n",
        "\n",
        "실험 방법 : 각 모델마다 동일한 vocab_size로 학습 진행 후 예측 정확도(macro f1-score) 계산\n",
        "\n",
        "산출물 : 모델에 따른 정확도 막대 그래프와 macro-f1-score 막대 그래프"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81e38a66",
      "metadata": {
        "id": "81e38a66"
      },
      "source": [
        "## Vocab Size에 따라 모델 성능이 달라질 것이다.\n",
        "통제 변인 : 모델 종류, 전처리 방식, 사용 데이터\n",
        "\n",
        "종속 변인 : vocab_size = [3000, 5000, 10000, 20000]\n",
        "\n",
        "실험 방법 : vocab_size에 따라 모델 학습 진행 후 예측 정확도(macro f1-score) 계산\n",
        "\n",
        "산출물 : 각 모델 별 vocab_size에 따른 정확도 그래프와 macro f1-score 그래프"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 가설 3\n",
        "통제 변인 :\n",
        "\n",
        "종속 변인 :\n",
        "\n",
        "실험 방법 :"
      ],
      "metadata": {
        "id": "DiK2FrbX_eba"
      },
      "id": "DiK2FrbX_eba"
    },
    {
      "cell_type": "markdown",
      "id": "6e7ecd28",
      "metadata": {
        "id": "6e7ecd28"
      },
      "source": [
        "# 모델 구현(1D-CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시퀀스 입력, 임베딩 없는 1D-CNN\n",
        "- 변인 통제에만 집중하여 모델의 특성을 고려하지 않은 채로 실험을 진행함.\n",
        "- 딥러닝 모델의 경우 토큰의 순서를 함께 학습해야 성능이 올라간다고 함."
      ],
      "metadata": {
        "id": "8cbsvt4njWCr"
      },
      "id": "8cbsvt4njWCr"
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN1D(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, num_filters=128, kernel_size=5):\n",
        "        super().__init__()\n",
        "        # X shape: (batch, input_dim) -> (batch, 1, input_dim)\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=1,\n",
        "            out_channels=num_filters,\n",
        "            kernel_size=kernel_size\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(num_filters, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, input_dim)\n",
        "        x = x.unsqueeze(1)               # (batch, 1, input_dim)\n",
        "        x = self.conv(x)                 # (batch, C, L')\n",
        "        x = self.relu(x)\n",
        "        x = torch.max(x, dim=2).values   # global max pooling -> (batch, C)\n",
        "        logits = self.fc(x)              # (batch, num_classes)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "JkdI9EVSQw1j"
      },
      "id": "JkdI9EVSQw1j",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN1DClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_epochs=5,\n",
        "        batch_size=64,\n",
        "        lr=1e-3,\n",
        "        verbose=1,\n",
        "        device=None,\n",
        "    ):\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.verbose = verbose\n",
        "        self.device = device if device is not None else (\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "\n",
        "        # 나중에 fit에서 채워지는 속성들\n",
        "        self.model_ = None\n",
        "        self.input_dim_ = None\n",
        "        self.num_classes_ = None\n",
        "\n",
        "    def _build_model(self, input_dim, num_classes):\n",
        "        self.model_ = SimpleCNN1D(\n",
        "            input_dim=input_dim,\n",
        "            num_classes=num_classes\n",
        "        ).to(self.device)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"X: TF-IDF (sparse or dense), y: label 배열\"\"\"\n",
        "        # 1) 입력/레이블 차원 파악\n",
        "        if hasattr(X, \"shape\"):\n",
        "            n_samples, input_dim = X.shape\n",
        "        else:\n",
        "            X = np.asarray(X)\n",
        "            n_samples, input_dim = X.shape\n",
        "\n",
        "        y = np.asarray(y)\n",
        "        num_classes = int(y.max()) + 1\n",
        "\n",
        "        self.input_dim_ = input_dim\n",
        "        self.num_classes_ = num_classes\n",
        "\n",
        "        # 2) PyTorch 텐서로 변환 (sparse면 dense로 변환)\n",
        "        if hasattr(X, \"toarray\"):  # scipy.sparse\n",
        "            X_tensor = torch.tensor(X.toarray(), dtype=torch.float32)\n",
        "        else:\n",
        "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        # 3) 모델/옵티마이저/손실함수 준비 (매 fit마다 새로 초기화)\n",
        "        self._build_model(input_dim, num_classes)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.model_.parameters(), lr=self.lr)\n",
        "\n",
        "        self.model_.train()\n",
        "        for epoch in range(self.num_epochs):\n",
        "            epoch_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for xb, yb in loader:\n",
        "                xb = xb.to(self.device)\n",
        "                yb = yb.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                logits = self.model_(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item() * xb.size(0)\n",
        "                preds = logits.argmax(dim=1)\n",
        "                correct += (preds == yb).sum().item()\n",
        "                total += xb.size(0)\n",
        "\n",
        "            if self.verbose:\n",
        "                print(\n",
        "                    f\"[CNN1D] Epoch {epoch+1}/{self.num_epochs} \"\n",
        "                    f\"Loss: {epoch_loss / total:.4f}  Acc: {correct / total:.4f}\"\n",
        "                )\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"sklearn의 predict 인터페이스\"\"\"\n",
        "        if hasattr(X, \"toarray\"):  # sparse\n",
        "            X_tensor = torch.tensor(X.toarray(), dtype=torch.float32)\n",
        "        else:\n",
        "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "        self.model_.eval()\n",
        "        preds = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, X_tensor.size(0), self.batch_size):\n",
        "                xb = X_tensor[i : i + self.batch_size].to(self.device)\n",
        "                logits = self.model_(xb)\n",
        "                batch_preds = logits.argmax(dim=1).cpu().numpy()\n",
        "                preds.append(batch_preds)\n",
        "\n",
        "        preds = np.concatenate(preds, axis=0)\n",
        "        return preds"
      ],
      "metadata": {
        "id": "t_QyiQx5Q0Tb"
      },
      "id": "t_QyiQx5Q0Tb",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시퀀스 입력 + 임베딩 추가"
      ],
      "metadata": {
        "id": "mgnhka04mJlT"
      },
      "id": "mgnhka04mJlT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기존 1D-CNN에서 변경된 부분\n",
        "\n",
        "- vocab 구성할 때, TF-IDF 기반으로 진행\n",
        "- sikit-learn에서 사용하는 fit() 함수로 명칭 변경"
      ],
      "metadata": {
        "id": "K853b5WWwh-h"
      },
      "id": "K853b5WWwh-h"
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_ID = 0       # 0: <unk> + pad\n",
        "MAX_SEQ_LEN = 300\n",
        "\n",
        "def build_sequences_from_vectorizer(texts, vectorizer, unk_id=UNK_ID):\n",
        "    \"\"\"\n",
        "    TF-IDF에 사용된 vectorizer의 analyzer와 vocab을 그대로 사용해서\n",
        "    TextCNN용 정수 시퀀스를 만든다.\n",
        "    - texts: 리스트[str]\n",
        "    - vectorizer: CountVectorizer (fit 완료)\n",
        "    return: (sequences, vocab_size_for_textcnn)\n",
        "    \"\"\"\n",
        "    analyzer = vectorizer.build_analyzer()  # CountVectorizer와 동일한 전처리/토크나이저\n",
        "    vocab_words = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # TextCNN용 word_index: 1..V까지 할당 (0은 pad/unk)\n",
        "    word_index = {w: i+1 for i, w in enumerate(vocab_words)}\n",
        "\n",
        "    sequences = []\n",
        "    for text in texts:\n",
        "        tokens = analyzer(text)\n",
        "        ids = [word_index.get(tok, unk_id) for tok in tokens]\n",
        "        sequences.append(ids)\n",
        "    vocab_size_for_textcnn = len(word_index) + 1  # 0 포함한 전체 크기\n",
        "    return sequences, vocab_size_for_textcnn\n",
        "\n",
        "def pad_sequences(seqs, maxlen, padding_value=UNK_ID):\n",
        "    padded = np.full((len(seqs), maxlen), padding_value, dtype=np.int64)\n",
        "    for i, s in enumerate(seqs):\n",
        "        trunc = s[:maxlen]\n",
        "        padded[i, :len(trunc)] = trunc\n",
        "    return padded"
      ],
      "metadata": {
        "id": "wJ1HDnRkwiAl"
      },
      "id": "wJ1HDnRkwiAl",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embed_dim,\n",
        "        num_classes,\n",
        "        filter_sizes=(3, 4, 5),\n",
        "        num_filters=100,\n",
        "        dropout=0.5,\n",
        "        padding_idx=UNK_ID,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embed_dim,\n",
        "            padding_idx=padding_idx,\n",
        "        )\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(\n",
        "                in_channels=embed_dim,\n",
        "                out_channels=num_filters,\n",
        "                kernel_size=fs\n",
        "            )\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len)\n",
        "        x = self.embedding(x)        # (batch, seq_len, embed_dim)\n",
        "        x = x.transpose(1, 2)        # (batch, embed_dim, seq_len)\n",
        "\n",
        "        conv_outs = []\n",
        "        for conv in self.convs:\n",
        "            c = torch.relu(conv(x))          # (batch, num_filters, L')\n",
        "            c = torch.max(c, dim=2).values   # (batch, num_filters)\n",
        "            conv_outs.append(c)\n",
        "\n",
        "        x = torch.cat(conv_outs, dim=1)      # (batch, num_filters * len(filter_sizes))\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x)                  # (batch, num_classes)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "zF4MmnsjwiEd"
      },
      "id": "zF4MmnsjwiEd",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCNNClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        num_classes,\n",
        "        embed_dim=128,\n",
        "        filter_sizes=(3, 4, 5),\n",
        "        num_filters=100,\n",
        "        dropout=0.5,\n",
        "        batch_size=64,\n",
        "        num_epochs=10,\n",
        "        lr=1e-3,\n",
        "        device=None,\n",
        "        verbose=1,\n",
        "    ):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_classes = num_classes\n",
        "        self.embed_dim = embed_dim\n",
        "        self.filter_sizes = filter_sizes\n",
        "        self.num_filters = num_filters\n",
        "        self.dropout = dropout\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.lr = lr\n",
        "        self.device = device if device is not None else (\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        self.verbose = verbose\n",
        "        self.model_ = None\n",
        "\n",
        "    def _build_model(self):\n",
        "        self.model_ = TextCNN(\n",
        "            vocab_size=self.vocab_size,\n",
        "            embed_dim=self.embed_dim,\n",
        "            num_classes=self.num_classes,\n",
        "            filter_sizes=self.filter_sizes,\n",
        "            num_filters=self.num_filters,\n",
        "            dropout=self.dropout,\n",
        "            padding_idx=UNK_ID,\n",
        "        ).to(self.device)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        X = np.asarray(X, dtype=np.int64)\n",
        "        y = np.asarray(y, dtype=np.int64)\n",
        "\n",
        "        train_ds = TensorDataset(\n",
        "            torch.tensor(X, dtype=torch.long),\n",
        "            torch.tensor(y, dtype=torch.long),\n",
        "        )\n",
        "        train_loader = DataLoader(train_ds, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        if X_val is not None and y_val is not None:\n",
        "            X_val = np.asarray(X_val, dtype=np.int64)\n",
        "            y_val = np.asarray(y_val, dtype=np.int64)\n",
        "            val_ds = TensorDataset(\n",
        "                torch.tensor(X_val, dtype=torch.long),\n",
        "                torch.tensor(y_val, dtype=torch.long),\n",
        "            )\n",
        "            val_loader = DataLoader(val_ds, batch_size=self.batch_size, shuffle=False)\n",
        "        else:\n",
        "            val_loader = None\n",
        "\n",
        "        self._build_model()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.model_.parameters(), lr=self.lr)\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.model_.train()\n",
        "            total_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for xb, yb in train_loader:\n",
        "                xb = xb.to(self.device)\n",
        "                yb = yb.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                logits = self.model_(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item() * xb.size(0)\n",
        "                preds = logits.argmax(dim=1)\n",
        "                correct += (preds == yb).sum().item()\n",
        "                total += xb.size(0)\n",
        "\n",
        "            msg = \"\"\n",
        "            if total > 0:\n",
        "                train_loss = total_loss / total\n",
        "                train_acc = correct / total\n",
        "                msg = f\"[TextCNN] Epoch {epoch+1}/{self.num_epochs}  loss={train_loss:.4f}  acc={train_acc:.4f}\"\n",
        "\n",
        "            if val_loader is not None:\n",
        "                val_acc, val_loss = self._eval_on_loader(val_loader, criterion)\n",
        "                msg += f\"  val_loss={val_loss:.4f}  val_acc={val_acc:.4f}\"\n",
        "\n",
        "            if self.verbose and msg:\n",
        "                print(msg)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _eval_on_loader(self, loader, criterion):\n",
        "        self.model_.eval()\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in loader:\n",
        "                xb = xb.to(self.device)\n",
        "                yb = yb.to(self.device)\n",
        "                logits = self.model_(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "\n",
        "                total_loss += loss.item() * xb.size(0)\n",
        "                preds = logits.argmax(dim=1)\n",
        "                correct += (preds == yb).sum().item()\n",
        "                total += xb.size(0)\n",
        "\n",
        "        return correct / total, total_loss / total\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.asarray(X, dtype=np.int64)\n",
        "        ds = TensorDataset(torch.tensor(X, dtype=torch.long))\n",
        "        loader = DataLoader(ds, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        self.model_.eval()\n",
        "        all_preds = []\n",
        "        with torch.no_grad():\n",
        "            for (xb,) in loader:\n",
        "                xb = xb.to(self.device)\n",
        "                logits = self.model_(xb)\n",
        "                preds = logits.argmax(dim=1).cpu().numpy()\n",
        "                all_preds.append(preds)\n",
        "\n",
        "        return np.concatenate(all_preds, axis=0)"
      ],
      "metadata": {
        "id": "Obe8UW71wiIj"
      },
      "id": "Obe8UW71wiIj",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test  = np.array(y_test)\n",
        "\n",
        "N = len(x_train)\n",
        "all_idx = np.arange(N)\n",
        "train_idx, val_idx = train_test_split(\n",
        "    all_idx,\n",
        "    test_size=0.2,\n",
        "    stratify=y_train,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "3QnWgXprwiSp"
      },
      "id": "3QnWgXprwiSp",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V5l2yvYswiUz"
      },
      "id": "V5l2yvYswiUz",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-stT774PwiXR"
      },
      "id": "-stT774PwiXR",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RRGtdOjwiaD"
      },
      "id": "2RRGtdOjwiaD",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d185f58b",
      "metadata": {
        "id": "d185f58b"
      },
      "source": [
        "# 모델 학습 파이프라인 설계\n",
        "- 입력 : 모델 리스트\n",
        "- 출력 : 모델 별, vocab_size 별 - 정확도, f1-macro-score 표, 가설 1, 2에 대한 시각화 그래프"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72a36bbc",
      "metadata": {
        "id": "72a36bbc"
      },
      "source": [
        "# 모델 학습 함수 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52991cb2",
      "metadata": {
        "id": "52991cb2"
      },
      "source": [
        "## train 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(models_dict, X_train, y_train):\n",
        "    \"\"\"\n",
        "    models_dict: {\"name\": model, ...}\n",
        "    X_train: TF-IDF 행렬 (sparse)\n",
        "    y_train: 라벨\n",
        "    \"\"\"\n",
        "    for name, model in models_dict.items():\n",
        "        print(f\"[{name}] fit started\")\n",
        "        model.fit(X_train, y_train)\n",
        "        print(f\"[{name}] fit finished\")\n",
        "    return models_dict"
      ],
      "metadata": {
        "id": "hPQ6LfxJNJEC"
      },
      "id": "hPQ6LfxJNJEC",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "43071e1c",
      "metadata": {
        "id": "43071e1c"
      },
      "source": [
        "## 모델 평가 지표 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_f1_macro(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    단일 모델에 대해 accuracy, macro F1 계산\n",
        "    \"\"\"\n",
        "    predicted = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, predicted)\n",
        "    macro_f1 = f1_score(y_test, predicted, average='macro')\n",
        "    print(\"정확도:\", acc)\n",
        "    print(\"Macro F1-score:\", macro_f1)\n",
        "    return acc, macro_f1"
      ],
      "metadata": {
        "id": "mGHfIlduMkpT"
      },
      "id": "mGHfIlduMkpT",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f907d263",
      "metadata": {
        "id": "f907d263"
      },
      "source": [
        "## 시각화 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics_by_vocab(\n",
        "    df,\n",
        "    exclude_minus_one: bool = True,\n",
        "    include_models: list[str] | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    df: model, vocab_size, accuracy, macro_f1 컬럼을 가진 DataFrame\n",
        "    exclude_minus_one: vocab_size == -1 (full vocab) 제거할지 여부\n",
        "    include_models: 특정 모델만 보고 싶을 때 리스트로 지정 (예: [\"Logistic Regression\", \"TextCNN\"])\n",
        "                    None이면 df에 있는 모든 모델 사용\n",
        "    \"\"\"\n",
        "\n",
        "    data = df.copy()\n",
        "\n",
        "    # 1) vocab_size -1 제거 옵션 (full vocab 제외)\n",
        "    if exclude_minus_one:\n",
        "        data = data[data[\"vocab_size\"] != -1]\n",
        "\n",
        "    if data.empty:\n",
        "        print(\"⚠ 필터링 후 남은 데이터가 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # 2) 사용할 모델 목록 결정\n",
        "    all_models = list(data[\"model\"].unique())\n",
        "\n",
        "    if include_models is not None:\n",
        "        # include_models에 있는 이름만, 그리고 실제로 df에 존재하는 모델만\n",
        "        model_names = [m for m in include_models if m in all_models]\n",
        "    else:\n",
        "        model_names = all_models\n",
        "\n",
        "    if not model_names:\n",
        "        print(\"⚠ 플로팅할 모델이 없습니다. (include_models / df 내용을 확인하세요)\")\n",
        "        return\n",
        "\n",
        "    num_models = len(model_names)\n",
        "\n",
        "    # 3) subplot: 2행 × N열 (1행 = accuracy, 2행 = macro_f1)\n",
        "    fig, axes = plt.subplots(\n",
        "        2,\n",
        "        num_models,\n",
        "        figsize=(5 * num_models, 8),\n",
        "        squeeze=False\n",
        "    )\n",
        "\n",
        "    for idx, model in enumerate(model_names):\n",
        "        temp = data[data[\"model\"] == model].sort_values(\"vocab_size\")\n",
        "\n",
        "        vocab = temp[\"vocab_size\"]\n",
        "        acc = temp[\"accuracy\"]\n",
        "        f1 = temp[\"macro_f1\"]\n",
        "\n",
        "        # ---- 1행: Accuracy ----\n",
        "        ax_acc = axes[0, idx]\n",
        "        ax_acc.plot(vocab, acc, marker=\"o\")\n",
        "        ax_acc.set_title(f\"[{model}] Accuracy\")\n",
        "        ax_acc.set_xlabel(\"Vocab Size\")\n",
        "        ax_acc.set_ylabel(\"Accuracy\")\n",
        "        ax_acc.grid(True)\n",
        "\n",
        "        # ---- 2행: Macro F1 ----\n",
        "        ax_f1 = axes[1, idx]\n",
        "        ax_f1.plot(vocab, f1, marker=\"o\")\n",
        "        ax_f1.set_title(f\"[{model}] Macro F1-score\")\n",
        "        ax_f1.set_xlabel(\"Vocab Size\")\n",
        "        ax_f1.set_ylabel(\"Macro F1-score\")\n",
        "        ax_f1.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "h1Z4biGSMj_U"
      },
      "id": "h1Z4biGSMj_U",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e3759115",
      "metadata": {
        "id": "e3759115"
      },
      "source": [
        "# 모델 학습 및 실험"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN-1D는 임베딩, 시퀀스 입력 무시한 CNN으로 tfidfv를 입력으로 받을 수 있음.\n",
        "\n",
        "# def build_models():\n",
        "#     return {\n",
        "#         \"Multinomial Naive Bayse\": MultinomialNB(),\n",
        "#         \"Complement Naive Bayse\": ComplementNB(),\n",
        "#         \"Logistic Regression\": LogisticRegression(C=10000, penalty='l2', max_iter=3000),\n",
        "#         \"Support Vector Machine\": LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False),\n",
        "#         \"Decision Tree\": DecisionTreeClassifier(max_depth=10, random_state=0),\n",
        "#         \"Random Forest\": RandomForestClassifier(n_estimators=5, random_state=0),\n",
        "#         \"Gradient Boosting\": GradientBoostingClassifier(random_state=0),\n",
        "#         \"Voting\": VotingClassifier(\n",
        "#             estimators=[\n",
        "#                 ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "#                 ('cb', ComplementNB()),\n",
        "#                 ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "#             ],\n",
        "#             voting='soft',\n",
        "#             n_jobs=-1\n",
        "#         ),\n",
        "#         # 이 CNN1DClassifier는 TF-IDF sparse 입력을 받도록 구현되어 있어야 함\n",
        "#         \"CNN-1D\": CNN1DClassifier(num_epochs=5, batch_size=64, lr=1e-3, verbose=1),\n",
        "#     }\n",
        "\n",
        "def build_models():\n",
        "    return {\n",
        "        \"Logistic Regression\": LogisticRegression(C=10000, penalty='l2', max_iter=3000),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=5, random_state=0)\n",
        "    }"
      ],
      "metadata": {
        "id": "0KaQ3Q8EXJwT"
      },
      "id": "0KaQ3Q8EXJwT",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_sizes = [1000, 1500, 3000, 5000, 10000, 20000, 30000, None] # 여력이 된다면 1000도 추가 진행, 전체 단어의 몇 %가 가장 최적인지 확인해보기\n",
        "results = []\n",
        "\n",
        "num_classes = int(y_train.max()) + 1"
      ],
      "metadata": {
        "id": "92CWwgfbSqiD"
      },
      "id": "92CWwgfbSqiD",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for v in vocab_sizes:\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"===== vocab_size = {v} =====\")\n",
        "    print(f\"==============================\")\n",
        "\n",
        "    # 1) TF-IDF + ML/CNN1D -----------------------------------\n",
        "    tfidfv, tfidfv_test, vectorizer = build_tfidf(x_train, x_test, max_features=v)\n",
        "\n",
        "    models_dict = build_models()\n",
        "    trained_models = model_train(models_dict, tfidfv, y_train)\n",
        "\n",
        "    for name, model in trained_models.items():\n",
        "        print(f\"\\n[TF-IDF / {name}]\")\n",
        "        acc, f1 = accuracy_f1_macro(model, tfidfv_test, y_test)\n",
        "        results.append({\n",
        "            \"model\": name,\n",
        "            \"type\": \"TFIDF\",\n",
        "            \"vocab_size\": v if v is not None else -1,\n",
        "            \"accuracy\": acc,\n",
        "            \"macro_f1\": f1,\n",
        "        })\n",
        "\n",
        "    # 2) 같은 vocab을 사용하는 TextCNN -----------------------\n",
        "    train_seqs, seq_vocab_size = build_sequences_from_vectorizer(x_train, vectorizer)\n",
        "    test_seqs, _               = build_sequences_from_vectorizer(x_test,  vectorizer)\n",
        "\n",
        "    X_train_pad = pad_sequences(train_seqs, MAX_SEQ_LEN)\n",
        "    X_test_pad  = pad_sequences(test_seqs,  MAX_SEQ_LEN)\n",
        "\n",
        "    X_tr  = X_train_pad[train_idx]\n",
        "    y_tr_ = y_train[train_idx]\n",
        "    X_val = X_train_pad[val_idx]\n",
        "    y_val_ = y_train[val_idx]\n",
        "\n",
        "    print(f\"\\n[TextCNN] training with tfidf_vocab_size={v}, textcnn_vocab_size={seq_vocab_size}\")\n",
        "\n",
        "    textcnn = TextCNNClassifier(\n",
        "        vocab_size=seq_vocab_size,\n",
        "        num_classes=num_classes,\n",
        "        embed_dim=128,\n",
        "        filter_sizes=(3, 4, 5),\n",
        "        num_filters=100,\n",
        "        dropout=0.5,\n",
        "        batch_size=64,\n",
        "        num_epochs=10,   # 시간보고 조절 가능\n",
        "        lr=1e-3,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    textcnn.fit(X_tr, y_tr_, X_val=X_val, y_val=y_val_)\n",
        "    y_pred = textcnn.predict(X_test_pad)\n",
        "\n",
        "    acc_tc = accuracy_score(y_test, y_pred)\n",
        "    f1_tc = f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "    print(f\"[TextCNN] test accuracy={acc_tc:.4f}, macro_f1={f1_tc:.4f}\")\n",
        "\n",
        "    results.append({\n",
        "        \"model\": \"TextCNN\",\n",
        "        \"type\": \"TextCNN\",\n",
        "        \"vocab_size\": v if v is not None else -1,\n",
        "        \"accuracy\": acc_tc,\n",
        "        \"macro_f1\": f1_tc,\n",
        "    })\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# 8. 결과 정리 및 저장\n",
        "# ======================================\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"all_models_tfidf_textcnn_same_vocab.csv\", index=False)\n",
        "print(\"\\n=== 전체 결과 ===\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k5UjL4hRSgr",
        "outputId": "b3134fee-fc40-4861-9ee1-1b53bc65934e"
      },
      "id": "4k5UjL4hRSgr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "===== vocab_size = 1000 =====\n",
            "==============================\n",
            "[Logistic Regression] fit started\n",
            "[Logistic Regression] fit finished\n",
            "[Random Forest] fit started\n",
            "[Random Forest] fit finished\n",
            "\n",
            "[TF-IDF / Logistic Regression]\n",
            "정확도: 0.7497773820124666\n",
            "Macro F1-score: 0.54531700045286\n",
            "\n",
            "[TF-IDF / Random Forest]\n",
            "정확도: 0.7105966162065895\n",
            "Macro F1-score: 0.3293343839879121\n",
            "\n",
            "[TextCNN] training with tfidf_vocab_size=1000, textcnn_vocab_size=1001\n",
            "[TextCNN] Epoch 1/10  loss=2.0147  acc=0.5246  val_loss=1.4031  val_acc=0.7001\n",
            "[TextCNN] Epoch 2/10  loss=1.4187  acc=0.6724  val_loss=1.1581  val_acc=0.7318\n",
            "[TextCNN] Epoch 3/10  loss=1.1677  acc=0.7247  val_loss=0.9885  val_acc=0.7785\n",
            "[TextCNN] Epoch 4/10  loss=1.0145  acc=0.7595  val_loss=0.9069  val_acc=0.7841\n",
            "[TextCNN] Epoch 5/10  loss=0.8999  acc=0.7781  val_loss=0.8656  val_acc=0.7997\n",
            "[TextCNN] Epoch 6/10  loss=0.8101  acc=0.7990  val_loss=0.8320  val_acc=0.7991\n",
            "[TextCNN] Epoch 7/10  loss=0.7208  acc=0.8135  val_loss=0.8162  val_acc=0.8075\n",
            "[TextCNN] Epoch 8/10  loss=0.6550  acc=0.8292  val_loss=0.7882  val_acc=0.8125\n",
            "[TextCNN] Epoch 9/10  loss=0.6028  acc=0.8433  val_loss=0.7784  val_acc=0.8164\n",
            "[TextCNN] Epoch 10/10  loss=0.5532  acc=0.8534  val_loss=0.7781  val_acc=0.8147\n",
            "[TextCNN] test accuracy=0.8077, macro_f1=0.5016\n",
            "\n",
            "==============================\n",
            "===== vocab_size = 1500 =====\n",
            "==============================\n",
            "[Logistic Regression] fit started\n",
            "[Logistic Regression] fit finished\n",
            "[Random Forest] fit started\n",
            "[Random Forest] fit finished\n",
            "\n",
            "[TF-IDF / Logistic Regression]\n",
            "정확도: 0.773820124666073\n",
            "Macro F1-score: 0.6270365488992387\n",
            "\n",
            "[TF-IDF / Random Forest]\n",
            "정확도: 0.7141585040071238\n",
            "Macro F1-score: 0.37630988851575464\n",
            "\n",
            "[TextCNN] training with tfidf_vocab_size=1500, textcnn_vocab_size=1501\n",
            "[TextCNN] Epoch 1/10  loss=2.0288  acc=0.5197  val_loss=1.4243  val_acc=0.6873\n",
            "[TextCNN] Epoch 2/10  loss=1.4548  acc=0.6579  val_loss=1.1391  val_acc=0.7462\n",
            "[TextCNN] Epoch 3/10  loss=1.1710  acc=0.7228  val_loss=0.9763  val_acc=0.7807\n",
            "[TextCNN] Epoch 4/10  loss=1.0105  acc=0.7567  val_loss=0.9127  val_acc=0.7902\n",
            "[TextCNN] Epoch 5/10  loss=0.9164  acc=0.7723  val_loss=0.8427  val_acc=0.8024\n",
            "[TextCNN] Epoch 6/10  loss=0.8010  acc=0.8021  val_loss=0.8067  val_acc=0.8130\n",
            "[TextCNN] Epoch 7/10  loss=0.7258  acc=0.8182  val_loss=0.7892  val_acc=0.8125\n",
            "[TextCNN] Epoch 8/10  loss=0.6614  acc=0.8315  val_loss=0.7749  val_acc=0.8214\n",
            "[TextCNN] Epoch 9/10  loss=0.5834  acc=0.8480  val_loss=0.7804  val_acc=0.8180\n",
            "[TextCNN] Epoch 10/10  loss=0.5385  acc=0.8610  val_loss=0.7544  val_acc=0.8258\n",
            "[TextCNN] test accuracy=0.8090, macro_f1=0.5216\n",
            "\n",
            "==============================\n",
            "===== vocab_size = 3000 =====\n",
            "==============================\n",
            "[Logistic Regression] fit started\n",
            "[Logistic Regression] fit finished\n",
            "[Random Forest] fit started\n",
            "[Random Forest] fit finished\n",
            "\n",
            "[TF-IDF / Logistic Regression]\n",
            "정확도: 0.790293855743544\n",
            "Macro F1-score: 0.6476152240926616\n",
            "\n",
            "[TF-IDF / Random Forest]\n",
            "정확도: 0.713713268032057\n",
            "Macro F1-score: 0.3463131097583759\n",
            "\n",
            "[TextCNN] training with tfidf_vocab_size=3000, textcnn_vocab_size=3001\n",
            "[TextCNN] Epoch 1/10  loss=2.0506  acc=0.5123  val_loss=1.4382  val_acc=0.6834\n",
            "[TextCNN] Epoch 2/10  loss=1.4523  acc=0.6607  val_loss=1.1612  val_acc=0.7379\n",
            "[TextCNN] Epoch 3/10  loss=1.2250  acc=0.7083  val_loss=1.0327  val_acc=0.7663\n",
            "[TextCNN] Epoch 4/10  loss=1.0614  acc=0.7498  val_loss=0.9443  val_acc=0.7807\n",
            "[TextCNN] Epoch 5/10  loss=0.9198  acc=0.7773  val_loss=0.8813  val_acc=0.7902\n",
            "[TextCNN] Epoch 6/10  loss=0.8490  acc=0.7887  val_loss=0.8265  val_acc=0.8030\n",
            "[TextCNN] Epoch 7/10  loss=0.7474  acc=0.8113  val_loss=0.8162  val_acc=0.8013\n",
            "[TextCNN] Epoch 8/10  loss=0.6585  acc=0.8278  val_loss=0.7946  val_acc=0.8047\n",
            "[TextCNN] Epoch 9/10  loss=0.5992  acc=0.8423  val_loss=0.7903  val_acc=0.8141\n",
            "[TextCNN] Epoch 10/10  loss=0.5281  acc=0.8612  val_loss=0.7576  val_acc=0.8236\n",
            "[TextCNN] test accuracy=0.8152, macro_f1=0.5638\n",
            "\n",
            "==============================\n",
            "===== vocab_size = 5000 =====\n",
            "==============================\n",
            "[Logistic Regression] fit started\n",
            "[Logistic Regression] fit finished\n",
            "[Random Forest] fit started\n",
            "[Random Forest] fit finished\n",
            "\n",
            "[TF-IDF / Logistic Regression]\n",
            "정확도: 0.8040961709706145\n",
            "Macro F1-score: 0.6506481798114472\n",
            "\n",
            "[TF-IDF / Random Forest]\n",
            "정확도: 0.6829919857524488\n",
            "Macro F1-score: 0.3033354596386591\n",
            "\n",
            "[TextCNN] training with tfidf_vocab_size=5000, textcnn_vocab_size=5001\n",
            "[TextCNN] Epoch 1/10  loss=2.0784  acc=0.5049  val_loss=1.4863  val_acc=0.6811\n",
            "[TextCNN] Epoch 2/10  loss=1.5180  acc=0.6413  val_loss=1.1981  val_acc=0.7318\n",
            "[TextCNN] Epoch 3/10  loss=1.2391  acc=0.7035  val_loss=1.0610  val_acc=0.7579\n",
            "[TextCNN] Epoch 4/10  loss=1.0719  acc=0.7424  val_loss=0.9574  val_acc=0.7774\n",
            "[TextCNN] Epoch 5/10  loss=0.9382  acc=0.7670  val_loss=0.8912  val_acc=0.7841\n",
            "[TextCNN] Epoch 6/10  loss=0.8551  acc=0.7879  val_loss=0.8399  val_acc=0.8080\n",
            "[TextCNN] Epoch 7/10  loss=0.7723  acc=0.8013  val_loss=0.8171  val_acc=0.8063\n",
            "[TextCNN] Epoch 8/10  loss=0.6663  acc=0.8274  val_loss=0.8131  val_acc=0.8086\n",
            "[TextCNN] Epoch 9/10  loss=0.6178  acc=0.8418  val_loss=0.7938  val_acc=0.8114\n",
            "[TextCNN] Epoch 10/10  loss=0.5433  acc=0.8507  val_loss=0.7741  val_acc=0.8114\n",
            "[TextCNN] test accuracy=0.8112, macro_f1=0.5278\n",
            "\n",
            "==============================\n",
            "===== vocab_size = 10000 =====\n",
            "==============================\n",
            "[Logistic Regression] fit started\n",
            "[Logistic Regression] fit finished\n",
            "[Random Forest] fit started\n",
            "[Random Forest] fit finished\n",
            "\n",
            "[TF-IDF / Logistic Regression]\n",
            "정확도: 0.8085485307212823\n",
            "Macro F1-score: 0.6534856836879375\n",
            "\n",
            "[TF-IDF / Random Forest]\n",
            "정확도: 0.674087266251113\n",
            "Macro F1-score: 0.30931816900485903\n",
            "\n",
            "[TextCNN] training with tfidf_vocab_size=10000, textcnn_vocab_size=9671\n",
            "[TextCNN] Epoch 1/10  loss=2.1256  acc=0.4913  val_loss=1.5122  val_acc=0.6505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "OP1g04sKPJRA"
      },
      "id": "OP1g04sKPJRA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = build_models()\n",
        "\n",
        "plot_metrics_by_vocab(results_df, models_dict=models, exclude_minus_one=True)"
      ],
      "metadata": {
        "id": "vW6z8dOPd1uG"
      },
      "id": "vW6z8dOPd1uG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4ba02022",
      "metadata": {
        "id": "4ba02022"
      },
      "source": [
        "# 결과"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qeyue3KEcnqW"
      },
      "id": "Qeyue3KEcnqW"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3MZkuBaUcoj2"
      },
      "id": "3MZkuBaUcoj2"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lxRHnPSVcpDP"
      },
      "id": "lxRHnPSVcpDP"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zILofAlScpXE"
      },
      "id": "zILofAlScpXE"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-mTXXTIncpq8"
      },
      "id": "-mTXXTIncpq8"
    },
    {
      "cell_type": "markdown",
      "id": "6138f0a4",
      "metadata": {
        "id": "6138f0a4"
      },
      "source": [
        "# 고찰"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44866da",
      "metadata": {
        "id": "d44866da"
      },
      "source": [
        "# 회고"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08fb0004",
      "metadata": {
        "id": "08fb0004"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8cbsvt4njWCr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}